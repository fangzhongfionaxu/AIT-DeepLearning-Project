{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84cb8457",
   "metadata": {
    "id": "84cb8457"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79edd04e",
   "metadata": {
    "id": "79edd04e"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7516bd99",
   "metadata": {
    "id": "7516bd99"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import when, regexp_extract, coalesce, col, lit\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
    "import holidays\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66bd005",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "f66bd005",
    "outputId": "d4069a80-364b-4606-991b-ec9e585731e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/27 13:16:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Set up & Load raw data\n",
    "spark = SparkSession.builder.appName(\"FlightPreprocessing\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"./Data/itineraries.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa69da3",
   "metadata": {
    "id": "2fa69da3",
    "outputId": "6592e88f-1018-4f92-fccf-3d30de936278"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data cleaning & Feature engineering\n",
    "columns_to_drop = [\n",
    "    'legId', 'totalFare', 'elapsedDays', 'fareBasisCode',\n",
    "    'segmentsAirlineCode', 'segmentsDepartureTimeEpochSeconds',\n",
    "    'segmentsArrivalTimeEpochSeconds', 'segmentsArrivalAirportCode',\n",
    "    'segmentsDepartureAirportCode', 'segmentsEquipmentDescription', 'segmentsDistance'\n",
    "]\n",
    "\n",
    "df = df.drop(*columns_to_drop)\n",
    "\n",
    "# isCoach\n",
    "flight_clean = df.withColumn(\n",
    "    'isCoach', F.when(F.col('segmentsCabinCode').contains('coach'), 1).otherwise(0)\n",
    ").drop('segmentsCabinCode')\n",
    "\n",
    "# days_until_flight\n",
    "flight_clean = flight_clean.withColumn(\n",
    "    'days_until_flight', F.datediff(F.to_date('flightDate'), F.to_date('searchDate'))\n",
    ")\n",
    "\n",
    "# holiday/weekend\n",
    "us_holidays = holidays.US(years=2024)\n",
    "holiday_dates = [d.strftime(\"%Y-%m-%d\") for d in us_holidays]\n",
    "flight_clean = flight_clean.withColumn(\"isHoliday\", F.when(F.col(\"flightDate\").isin(holiday_dates), 1).otherwise(0))\n",
    "flight_clean = flight_clean.withColumn(\"isWeekend\", F.when(F.dayofweek(\"flightDate\").isin([1, 7]), 1).otherwise(0))\n",
    "\n",
    "# Fill missing distance\n",
    "flight_clean = flight_clean.withColumn(\n",
    "    \"totalTravelDistance\",\n",
    "    when(col(\"totalTravelDistance\").rlike(\"^[0-9.]+$\"), col(\"totalTravelDistance\").cast(\"float\"))\n",
    "    .otherwise(None)\n",
    ")\n",
    "median_distance = flight_clean.approxQuantile(\"totalTravelDistance\", [0.5], 0.01)[0]\n",
    "flight_clean = flight_clean.fillna({\"totalTravelDistance\": median_distance})\n",
    "\n",
    "# Extract travel minutes\n",
    "flight_clean = flight_clean.withColumn(\n",
    "    \"hours\",\n",
    "    coalesce(regexp_extract(col(\"travelDuration\"), r\"(\\d+)H\", 1).cast(\"int\"), lit(0))\n",
    ").withColumn(\n",
    "    \"minutes\",\n",
    "    coalesce(regexp_extract(col(\"travelDuration\"), r\"(\\d+)M\", 1).cast(\"int\"), lit(0))\n",
    ")\n",
    "flight_clean = flight_clean.withColumn(\n",
    "    \"travelMinutes\",\n",
    "    col(\"hours\") * 60 + col(\"minutes\")\n",
    ")\n",
    "flight_clean = flight_clean.drop('travelDuration')\n",
    "\n",
    "# isNonstop\n",
    "flight_clean = flight_clean.withColumn(\"segmentsDurationArray\", F.split(\"segmentsDurationInSeconds\", r\"\\\\|\\\\|\"))\\\n",
    "    .withColumn(\"isNonstop\", F.when(F.size(\"segmentsDurationArray\") == 1, 1).otherwise(0))\\\n",
    "    .drop(\"segmentsDurationArray\", \"segmentsDurationInSeconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2a935d",
   "metadata": {
    "id": "7b2a935d",
    "outputId": "758c96c3-4b9b-4c0b-a6c6-993dd6edcc4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Temporal sort\n",
    "flight_clean = flight_clean.withColumn(\"departure_ts\", F.to_timestamp(\"segmentsDepartureTimeRaw\"))\\\n",
    "    .withColumn(\"departure_date\", F.to_date(\"departure_ts\"))\\\n",
    "    .orderBy(\"departure_date\")\n",
    "\n",
    "dates = flight_clean.select(\"departure_date\").distinct().orderBy(\"departure_date\")\n",
    "total_dates = dates.count()\n",
    "train_end_idx = int(total_dates * 0.7)\n",
    "val_end_idx = train_end_idx + int(total_dates * 0.15)\n",
    "\n",
    "train_dates = dates.limit(train_end_idx).collect()\n",
    "val_dates = dates.limit(val_end_idx).tail(val_end_idx - train_end_idx)\n",
    "test_dates = dates.tail(total_dates - val_end_idx)\n",
    "\n",
    "train_cutoff = train_dates[-1][\"departure_date\"]\n",
    "val_cutoff = val_dates[-1][\"departure_date\"]\n",
    "\n",
    "train_df = flight_clean.filter(F.col(\"departure_date\") <= train_cutoff)\n",
    "val_df = flight_clean.filter((F.col(\"departure_date\") > train_cutoff) & (F.col(\"departure_date\") <= val_cutoff))\n",
    "test_df = flight_clean.filter(F.col(\"departure_date\") > val_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "522b6d1d",
   "metadata": {
    "id": "522b6d1d",
    "outputId": "67c04b5a-015e-4fd2-8e05-ed084e96caf1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Encoding pipeline\n",
    "binary_cols = [\"isBasicEconomy\", \"isRefundable\", \"isNonstop\", \"isCoach\", \"isWeekend\", \"isHoliday\"]\n",
    "for colname in binary_cols:\n",
    "    train_df = train_df.withColumn(colname, F.col(colname).cast(\"int\"))\n",
    "    val_df = val_df.withColumn(colname, F.col(colname).cast(\"int\"))\n",
    "    test_df = test_df.withColumn(colname, F.col(colname).cast(\"int\"))\n",
    "\n",
    "categorical_cols = [\"startingAirport\", \"destinationAirport\", \"segmentsAirlineName\"]\n",
    "numerical_cols = [\"seatsRemaining\", \"totalTravelDistance\", \"travelMinutes\"]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\") for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_vec\") for col in categorical_cols]\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"num_features\")\n",
    "scaler = MinMaxScaler(inputCol=\"num_features\", outputCol=\"scaled_num_features\")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
    "pipeline_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1229cb9d",
   "metadata": {
    "id": "1229cb9d"
   },
   "outputs": [],
   "source": [
    "# Chunked transformation & Save\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "os.makedirs(os.path.join(base_dir, \"chunks\", \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, \"chunks\", \"val\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, \"chunks\", \"test\"), exist_ok=True)\n",
    "\n",
    "train_output_path = os.path.join(base_dir, \"chunks\", \"train\")\n",
    "val_output_path = os.path.join(base_dir, \"chunks\", \"val\")\n",
    "test_output_path = os.path.join(base_dir, \"chunks\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea6a1ec0",
   "metadata": {
    "id": "ea6a1ec0"
   },
   "outputs": [],
   "source": [
    "def transform_and_save_chunks(df, name_prefix, pipeline_model, chunk_size, output_dir):\n",
    "    df = df.orderBy(\"departure_date\")\n",
    "    dates = df.select(\"departure_date\").distinct().orderBy(\"departure_date\")\n",
    "    total_dates = dates.count()\n",
    "\n",
    "    for start in range(0, total_dates, chunk_size):\n",
    "        end = min(start + chunk_size, total_dates)\n",
    "        date_range = dates.limit(end).tail(chunk_size)\n",
    "        date_values = [row['departure_date'] for row in date_range]\n",
    "\n",
    "        chunk_df = df.filter(F.col(\"departure_date\").isin(date_values)).dropna(subset=[\"travelMinutes\"])\n",
    "        transformed = pipeline_model.transform(chunk_df)\n",
    "        to_drop = [col + \"_index\" for col in categorical_cols] + [\"num_features\"]\n",
    "        transformed = transformed.drop(*to_drop)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"{name_prefix}_chunk_{start}_{end}.parquet\")\n",
    "        transformed.write.mode(\"overwrite\").parquet(output_path)\n",
    "        print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ac7592d",
   "metadata": {
    "id": "8ac7592d",
    "outputId": "d0879750-958c-4fe7-81c3-7ce6e6620499"
   },
   "outputs": [],
   "source": [
    "transform_and_save_chunks(train_df, \"train\", pipeline_model, chunk_size=50, output_dir=train_output_path)\n",
    "transform_and_save_chunks(val_df, \"val\", pipeline_model, chunk_size=50, output_dir=val_output_path)\n",
    "transform_and_save_chunks(test_df, \"test\", pipeline_model, chunk_size=50, output_dir=test_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12425dc9",
   "metadata": {
    "id": "12425dc9"
   },
   "outputs": [],
   "source": [
    "class ChunkedFlightGenerator(Sequence):\n",
    "    def __init__(self, chunk_paths, batch_size=32, target_col=\"baseFare\", vector_size=10):\n",
    "        self.chunk_paths = chunk_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.target_col = target_col\n",
    "        self.vector_size = vector_size\n",
    "\n",
    "        # Load all data\n",
    "        self.data = pd.concat([pd.read_parquet(path) for path in chunk_paths], ignore_index=True)\n",
    "\n",
    "        # Extract 3 datetime-based features\n",
    "        self.data = self._extract_datetime_features(self.data)\n",
    "\n",
    "        # Drop raw string and datetime columns\n",
    "        columns_to_drop = [\n",
    "            'searchDate', 'flightDate', 'departure_ts',\n",
    "            'startingAirport', 'destinationAirport',\n",
    "            'segmentsDepartureTimeRaw', 'segmentsArrivalTimeRaw',\n",
    "            'segmentsAirlineName', 'departure_date'\n",
    "        ]\n",
    "        self.data.drop(columns=[col for col in columns_to_drop if col in self.data.columns], inplace=True)\n",
    "\n",
    "        # Vector columns to expand\n",
    "        self.vec_columns = [\n",
    "            'startingAirport_vec',\n",
    "            'destinationAirport_vec',\n",
    "            'segmentsAirlineName_vec',\n",
    "            'scaled_num_features'\n",
    "        ]\n",
    "        vec_expansions = [self._expand_vector_column(col) for col in self.vec_columns if col in self.data.columns]\n",
    "        self.data.drop(columns=self.vec_columns, inplace=True, errors='ignore')\n",
    "\n",
    "        # Numeric features (excluding target)\n",
    "        numeric_df = self.data.drop(columns=[self.target_col])\n",
    "        final_df = pd.concat([numeric_df] + vec_expansions, axis=1)\n",
    "        \n",
    "        print(list(final_df.columns))\n",
    "\n",
    "        # Final features and targets\n",
    "        self.X = final_df.astype(np.float32).values\n",
    "        self.y = self.data[self.target_col].astype(np.float32).values\n",
    "\n",
    "    def _expand_vector_column(self, col_name):\n",
    "        \"\"\"Expands a column of lists/vectors into multiple float32 columns.\"\"\"\n",
    "        # Fill NaNs with empty lists to avoid errors\n",
    "        self.data[col_name] = self.data[col_name].apply(lambda x: x if isinstance(x, (list, np.ndarray)) else [])\n",
    "\n",
    "        # Expand each vector into a fixed-length list\n",
    "        expanded = self.data[col_name].apply(self._pad_or_truncate)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        expanded_df = pd.DataFrame(expanded.tolist(), index=self.data.index)\n",
    "\n",
    "        # Rename columns\n",
    "        expanded_df.columns = [f\"{col_name}_{i}\" for i in range(expanded_df.shape[1])]\n",
    "        return expanded_df.astype(np.float32)\n",
    "\n",
    "    def _pad_or_truncate(self, vector):\n",
    "        \"\"\"Pads or truncates a list-like vector to self.vector_size.\"\"\"\n",
    "        if isinstance(vector, pd.Series) or isinstance(vector, np.ndarray):\n",
    "            vector = list(vector)\n",
    "        elif not isinstance(vector, list):\n",
    "            return [0.0] * self.vector_size\n",
    "\n",
    "        if len(vector) > self.vector_size:\n",
    "            return vector[:self.vector_size]\n",
    "        else:\n",
    "            return vector + [0.0] * (self.vector_size - len(vector))\n",
    "\n",
    "    def _extract_datetime_features(self, df):\n",
    "        \"\"\"Extracts specific datetime-derived features.\"\"\"\n",
    "        if 'searchDate' in df.columns:\n",
    "            df['searchDate'] = pd.to_datetime(df['searchDate'], errors='coerce')\n",
    "            df['searchDate_dayofweek'] = df['searchDate'].dt.dayofweek\n",
    "\n",
    "        if 'flightDate' in df.columns:\n",
    "            df['flightDate'] = pd.to_datetime(df['flightDate'], errors='coerce')\n",
    "            df['flightDate_month'] = df['flightDate'].dt.month\n",
    "\n",
    "        if 'departure_ts' in df.columns:\n",
    "            df['departure_ts'] = pd.to_datetime(df['departure_ts'], errors='coerce')\n",
    "            df['departure_ts_hour'] = df['departure_ts'].dt.hour\n",
    "\n",
    "        return df\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.X[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x[:, np.newaxis, :], batch_y  # Shape: (batch_size, 1, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ffeae95-419b-4d97-9c1c-eda3d30a5455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isBasicEconomy', 'isRefundable', 'isNonstop', 'seatsRemaining', 'totalTravelDistance', 'isCoach', 'days_until_flight', 'isHoliday', 'isWeekend', 'travelMinutes', 'hours', 'minutes', 'searchDate_dayofweek', 'flightDate_month', 'departure_ts_hour', 'startingAirport_vec_0', 'startingAirport_vec_1', 'startingAirport_vec_2', 'startingAirport_vec_3', 'startingAirport_vec_4', 'startingAirport_vec_5', 'startingAirport_vec_6', 'startingAirport_vec_7', 'startingAirport_vec_8', 'startingAirport_vec_9', 'destinationAirport_vec_0', 'destinationAirport_vec_1', 'destinationAirport_vec_2', 'destinationAirport_vec_3', 'destinationAirport_vec_4', 'destinationAirport_vec_5', 'destinationAirport_vec_6', 'destinationAirport_vec_7', 'destinationAirport_vec_8', 'destinationAirport_vec_9', 'segmentsAirlineName_vec_0', 'segmentsAirlineName_vec_1', 'segmentsAirlineName_vec_2', 'segmentsAirlineName_vec_3', 'segmentsAirlineName_vec_4', 'segmentsAirlineName_vec_5', 'segmentsAirlineName_vec_6', 'segmentsAirlineName_vec_7', 'segmentsAirlineName_vec_8', 'segmentsAirlineName_vec_9', 'scaled_num_features_0', 'scaled_num_features_1', 'scaled_num_features_2', 'scaled_num_features_3', 'scaled_num_features_4', 'scaled_num_features_5', 'scaled_num_features_6', 'scaled_num_features_7', 'scaled_num_features_8', 'scaled_num_features_9']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ChunkedFlightGenerator at 0xbc7e95ac0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen = ChunkedFlightGenerator(test_chunks)\n",
    "test_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aad2dd",
   "metadata": {
    "id": "02aad2dd"
   },
   "source": [
    "## Baseline 1: ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c23490f",
   "metadata": {
    "id": "6c23490f"
   },
   "source": [
    "## Baseline 2: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b72fa7e3-d465-47fb-901a-8a246987afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mtest\u001b[m\u001b[m  \u001b[34mtrain\u001b[m\u001b[m \u001b[34mval\u001b[m\u001b[m\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.0-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.0.0-py3-none-macosx_12_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!ls /Users/FionaXu/Documents/Wellesley/Academics/CleanAIT/AIT-DeepLearning-Project/chunks\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4eafe06-e52d-4ac3-a261-5f61c571547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fc9717d-f120-4731-8eb5-f8fd9938ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "base_dir = os.getcwd()\n",
    "train_chunk_dir = os.path.join(base_dir, \"chunks\", \"train\")\n",
    "val_chunk_dir = os.path.join(base_dir, \"chunks\", \"val\")\n",
    "test_chunk_dir = os.path.join(base_dir, \"chunks\", \"test\")\n",
    "\n",
    "train_chunks = sorted([\n",
    "    os.path.join(train_chunk_dir, f) for f in os.listdir(train_chunk_dir) if f.endswith(\".parquet\")\n",
    "])\n",
    "val_chunks = sorted([\n",
    "    os.path.join(val_chunk_dir, f) for f in os.listdir(val_chunk_dir) if f.endswith(\".parquet\")\n",
    "])\n",
    "test_chunks = sorted([\n",
    "    os.path.join(test_chunk_dir, f) for f in os.listdir(test_chunk_dir) if f.endswith(\".parquet\")\n",
    "])\n",
    "\n",
    "train_gen = ChunkedFlightGenerator(train_chunks)\n",
    "val_gen = ChunkedFlightGenerator(val_chunks)\n",
    "test_gen = ChunkedFlightGenerator(test_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e1fe4b3-696c-4552-aac2-e36f97dd7295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:132.94812\tvalidation_1-rmse:111.66591\n",
      "[100]\tvalidation_0-rmse:85.10060\tvalidation_1-rmse:78.27332\n",
      "[200]\tvalidation_0-rmse:81.82455\tvalidation_1-rmse:76.30521\n",
      "[300]\tvalidation_0-rmse:79.83114\tvalidation_1-rmse:75.12094\n",
      "[400]\tvalidation_0-rmse:78.50913\tvalidation_1-rmse:74.35494\n",
      "[500]\tvalidation_0-rmse:77.48806\tvalidation_1-rmse:74.00978\n",
      "[600]\tvalidation_0-rmse:76.66804\tvalidation_1-rmse:73.55495\n",
      "[700]\tvalidation_0-rmse:76.04662\tvalidation_1-rmse:73.32736\n",
      "[800]\tvalidation_0-rmse:75.43659\tvalidation_1-rmse:73.15420\n",
      "[900]\tvalidation_0-rmse:74.96725\tvalidation_1-rmse:72.96308\n",
      "[999]\tvalidation_0-rmse:74.55756\tvalidation_1-rmse:72.83462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = xgb.XGBRegressor(n_estimators=1000,early_stopping_rounds=50)\n",
    "X_train = train_gen.X\n",
    "y_train = train_gen.y\n",
    "\n",
    "X_val = val_gen.X\n",
    "y_val = val_gen.y\n",
    "\n",
    "\n",
    "\n",
    "reg.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        \n",
    "       verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d932aeea-7147-41d3-acef-cfa6dbc8e34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 5558.83\n",
      "Train MAE: 44.66\n",
      "Train R2: 0.7681\n",
      "Validation MSE: 5304.88\n",
      "Validation MAE: 43.87\n",
      "Validation R2: 0.6505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_val_pred = reg.predict(X_val)\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for validation set\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train MSE: {train_mse:.2f}\")\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Train R2: {train_r2:.4f}\")\n",
    "\n",
    "print(f\"Validation MSE: {val_mse:.2f}\")\n",
    "print(f\"Validation MAE: {val_mae:.2f}\")\n",
    "print(f\"Validation R2: {val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29188ea5-dbcb-4880-8e2e-d0c83d23cc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed5b1019",
   "metadata": {
    "id": "ed5b1019"
   },
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c187d7",
   "metadata": {
    "id": "05c187d7"
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "base_dir = os.getcwd()\n",
    "train_chunk_dir = os.path.join(base_dir, \"chunks\", \"train\")\n",
    "val_chunk_dir = os.path.join(base_dir, \"chunks\", \"val\")\n",
    "test_chunk_dir = os.path.join(base_dir, \"chunks\", \"test\")\n",
    "\n",
    "train_chunks = sorted([\n",
    "    os.path.join(train_chunk_dir, f) for f in os.listdir(train_chunk_dir) if f.endswith(\".parquet\")\n",
    "])\n",
    "val_chunks = sorted([\n",
    "    os.path.join(val_chunk_dir, f) for f in os.listdir(val_chunk_dir) if f.endswith(\".parquet\")\n",
    "])\n",
    "test_chunks = sorted([\n",
    "    os.path.join(test_chunk_dir, f) for f in os.listdir(test_chunk_dir) if f.endswith(\".parquet\")\n",
    "])\n",
    "\n",
    "train_gen = ChunkedFlightGenerator(train_chunks)\n",
    "val_gen = ChunkedFlightGenerator(val_chunks)\n",
    "test_gen = ChunkedFlightGenerator(test_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36bf0a",
   "metadata": {
    "id": "7e36bf0a",
    "outputId": "56d00ed6-426d-4864-8659-6e5ee8b6848b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hpanh/Library/Python/3.9/lib/python/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/hpanh/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m742753/742753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 898us/step - loss: 26025.8164 - val_loss: 14851.0352\n",
      "Epoch 2/5\n",
      "\u001b[1m742753/742753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 875us/step - loss: 18830.6934 - val_loss: 14194.5537\n",
      "Epoch 3/5\n",
      "\u001b[1m742753/742753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 894us/step - loss: 17291.7559 - val_loss: 13641.6836\n",
      "Epoch 4/5\n",
      "\u001b[1m742753/742753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 890us/step - loss: 17177.0996 - val_loss: 13826.0449\n",
      "Epoch 5/5\n",
      "\u001b[1m742753/742753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m763s\u001b[0m 1ms/step - loss: 16935.3184 - val_loss: 13769.9219\n",
      "\u001b[1m49114/49114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 669us/step\n",
      "Test MSE: 11205.9932\n",
      "Test MAE: 83.0002\n",
      "Test R²: -0.1239\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(16, input_shape=(1, train_gen.X.shape[1])),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=5)\n",
    "\n",
    "predictions = model.predict(test_gen, batch_size=128)\n",
    "y_true = np.concatenate(\n",
    "    [test_gen[i][1] for i in range(len(test_gen))],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"Test MSE: {mean_squared_error(y_true, predictions):.4f}\")\n",
    "print(f\"Test MAE: {mean_absolute_error(y_true, predictions):.4f}\")\n",
    "print(f\"Test R²: {r2_score(y_true, predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b66c07c",
   "metadata": {
    "id": "8b66c07c"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "42229a98-b32f-4b1b-9ce4-710945bd3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f186142a-7e63-497a-848b-23821891b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_feature_indices = [12, 13, 14]\n",
    "\n",
    "# Select only the time features\n",
    "X_train_time = X_train[:, time_feature_indices]\n",
    "X_val_time = X_val[:, time_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c7344e57-d1bb-4b22-868c-72d2e3c6a724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23768082, 3, 1)\n",
      "(23768082, 55)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_time.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0395291e-e81f-4d68-b4b9-9a5f801c4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 55      # because you have 3 time-related features\n",
    "n_features = 1  # because you have 55 features, including time-related ones\n",
    "\n",
    "X_train_lstm= X_train.reshape((X_train.shape[0], n_steps, n_features))\n",
    "X_val_lstm = X_val.reshape((X_val.shape[0], n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "15a31a68-b3ed-4396-a9d1-eebf17478e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', dropout=0.3, return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ac1f17f3-8d5b-45cb-9b62-7255dc75375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m742753/742753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m976s\u001b[0m 1ms/step - loss: 23784.2402 - mae: 103.6707 - mse: 23784.2402 - val_loss: 20160.6797 - val_mae: 110.5064 - val_mse: 20160.6797\n",
      "Epoch 2/3\n",
      "\u001b[1m742753/742753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m991s\u001b[0m 1ms/step - loss: 22837.7617 - mae: 101.6054 - mse: 22837.7617 - val_loss: 20494.2285 - val_mae: 110.9393 - val_mse: 20494.2285\n",
      "Epoch 3/3\n",
      "\u001b[1m742753/742753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1076s\u001b[0m 1ms/step - loss: 22848.5918 - mae: 101.6242 - mse: 22848.5918 - val_loss: 19966.8242 - val_mae: 109.2547 - val_mse: 19966.8242\n",
      "\u001b[1m164111/164111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 354us/step\n",
      "R² Score: -0.3154878616333008\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(\n",
    "    X_train_time,y_train,\n",
    "    epochs=3, \n",
    "    verbose=1, \n",
    "    validation_data=(X_val_time, y_val))\n",
    "\n",
    "# After training\n",
    "y_pred = model.predict(X_val_time)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d043dc",
   "metadata": {
    "id": "38d043dc"
   },
   "source": [
    "## GRU"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
