{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f2fbd5-5f17-42dd-a1c5-e1d2568ef618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70eca02e-91c1-4060-aec6-d7f1db4e8a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/lib/python3.12/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/anaconda3/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0d247b-a7a3-41ae-be63-12da585f25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f2e3080-c459-4859-91f1-35d025a5d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# german_df = pd.read_csv('./Data/GermanAirFares.csv')\n",
    "# main_df = pd.read_csv('./Data/itineraries.csv')\n",
    "# main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43b005d-fafc-4833-b713-0ff03aee8e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 3.5.5\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: /opt/anaconda3/lib/python3.12/site-packages\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bd6fe55-b574-4d43-9284-d3e237bb5952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/22 22:55:26 WARN Utils: Your hostname, Fiona-X-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.20.10.4 instead (on interface en0)\n",
      "25/03/22 22:55:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/22 22:55:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"FlightPricePrediction\").getOrCreate()\n",
    "\n",
    "# Read large CSV (distributed processing)\n",
    "df = spark.read.csv(\"./Data/itineraries.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f93a79c0-0a55-4715-a1b8-b52dd0804909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 100)\n",
    "spark.conf.get(\"spark.sql.debug.maxToStringFields\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65b71ba4-4772-46ec-9fb6-0ce01617cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4491fc17-1e89-4712-96f1-7dfde0f3133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+------------------+\n",
      "|searchDate|flightDate|startingAirport|destinationAirport|\n",
      "+----------+----------+---------------+------------------+\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "|2022-04-16|2022-04-17|ATL            |BOS               |\n",
      "+----------+----------+---------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.select(\"searchDate\",\"flightDate\", \"startingAirport\", \"destinationAirport\").show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09803d12-fe51-44c7-be60-0120d954b43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "num_starting_airports = flight_df.select(\"startingAirport\").distinct().count()\n",
    "num_airline_name = flight_df.select(\"segmentsAirlineName\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4ef4010-dad4-4e9c-9228-c5e074e5ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "num_cabin = flight_df.select(\"segmentsCabinCode\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19c85268-071d-42eb-a9b1-89991929288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:=====================================================>(229 + 3) / 232]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   segmentsCabinCode|\n",
      "+--------------------+\n",
      "|coach||coach||pre...|\n",
      "|coach||coach||coa...|\n",
      "|        first||coach|\n",
      "|premium coach||pr...|\n",
      "| coach||first||coach|\n",
      "|premium coach||co...|\n",
      "|               coach|\n",
      "|     coach||business|\n",
      "|premium coach||pr...|\n",
      "|premium coach||coach|\n",
      "| coach||coach||first|\n",
      "|coach||coach||fir...|\n",
      "|coach||coach||bus...|\n",
      "|coach||business||...|\n",
      "|     business||coach|\n",
      "|business||busines...|\n",
      "| coach||coach||coach|\n",
      "| first||coach||coach|\n",
      "|       premium coach|\n",
      "|        coach||first|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flight_df.select(\"segmentsCabinCode\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2982001a-af29-4129-850c-3da8ae551777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|  segmentsCabinCode|totalFare|\n",
      "+-------------------+---------+\n",
      "|      premium coach|    548.6|\n",
      "|      premium coach|    648.6|\n",
      "|      premium coach|    648.6|\n",
      "|      premium coach|   1048.6|\n",
      "|      premium coach|   1048.6|\n",
      "|first||coach||coach|   1389.1|\n",
      "|first||coach||coach|  1597.11|\n",
      "|      premium coach|    748.6|\n",
      "|      premium coach|    748.6|\n",
      "|      premium coach|    748.6|\n",
      "+-------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_filtered = flight_df.filter(col(\"segmentsCabinCode\").isin([\"first||coach||coach\",\"premium coach\"])).select(\"segmentsCabinCode\", \"totalFare\")\n",
    "df_filtered.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4738405-3c3b-4ca7-a170-89ad50bac553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
